{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Localized Semantic Editing of StyleGAN outputs\n",
    "\n",
    "Introduced in the paper:<br>\n",
    "> Edo Collins, Raja Bala, Bob Price and Sabine SÃ¼sstrunk. _Editing in Style: Uncovering the Local Semantics of GANs_.  IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020.\n",
    "\n",
    "This demo illustrates a simple and effective method for making local, semantically-aware edits to a _target_ GAN output image. This is accomplished by borrowing styles from a _source_ image, also a GAN output.\n",
    "\n",
    "The method requires neither supervision from an external model, nor involves complex spatial morphing operations. Instead, it relies on the emergent disentanglement of semantic objects that is learned by StyleGAN during its training, which we detect using Spherical _k_-means.\n",
    "\n",
    "The implementation below relies on PyTorch and requires downloading additional parameter files found here: https://drive.google.com/open?id=1GYzEzOCaI8FUS6JHdt6g9UfNTmpO08Tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from stylegan2 import Generator                            # StyleGAN model\n",
    "from stylegan2_output import GANOutputs              # Data structure to hold GAN outputs\n",
    "import ptutils                                      # Helper tensor functions\n",
    "import visutils                                     # Visualization functions\n",
    "from style2_interpolator import StyleInterpolator    # The 'sequential' style-interpolator (Eq. 5)\n",
    "import cielab                                       # Helper functions for CIELAB color-space\n",
    "\n",
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the appropriate StyleGAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'ffhq'\n",
    "config = 'E'\n",
    "channel = 1 if config == 'E' else 2\n",
    "root_dir = '../karras_ckpt' # See comment above regarding additional files\n",
    "if dataset_name == 'cat':\n",
    "    truncation = 0.5\n",
    "    size = 256\n",
    "elif dataset_name == 'ffhq':\n",
    "    truncation = 0.7\n",
    "    size = 1024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator(size, 512, 8, channel_multiplier=channel)\n",
    "G.load_state_dict(torch.load('{}/{}{}.pt'.format(root_dir, dataset_name, config))['g_ema'])\n",
    "G.eval()\n",
    "G = G.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "style.1.weight\n",
      "style.1.bias\n",
      "style.2.weight\n",
      "style.2.bias\n",
      "style.3.weight\n",
      "style.3.bias\n",
      "style.4.weight\n",
      "style.4.bias\n",
      "style.5.weight\n",
      "style.5.bias\n",
      "style.6.weight\n",
      "style.6.bias\n",
      "style.7.weight\n",
      "style.7.bias\n",
      "style.8.weight\n",
      "style.8.bias\n",
      "input.input\n",
      "conv1.conv.weight\n",
      "conv1.conv.modulation.weight\n",
      "conv1.conv.modulation.bias\n",
      "conv1.noise.weight\n",
      "conv1.activate.bias\n",
      "to_rgb1.bias\n",
      "to_rgb1.conv.weight\n",
      "to_rgb1.conv.modulation.weight\n",
      "to_rgb1.conv.modulation.bias\n",
      "convs.0.conv.weight\n",
      "convs.0.conv.blur.kernel\n",
      "convs.0.conv.modulation.weight\n",
      "convs.0.conv.modulation.bias\n",
      "convs.0.noise.weight\n",
      "convs.0.activate.bias\n",
      "convs.1.conv.weight\n",
      "convs.1.conv.modulation.weight\n",
      "convs.1.conv.modulation.bias\n",
      "convs.1.noise.weight\n",
      "convs.1.activate.bias\n",
      "convs.2.conv.weight\n",
      "convs.2.conv.blur.kernel\n",
      "convs.2.conv.modulation.weight\n",
      "convs.2.conv.modulation.bias\n",
      "convs.2.noise.weight\n",
      "convs.2.activate.bias\n",
      "convs.3.conv.weight\n",
      "convs.3.conv.modulation.weight\n",
      "convs.3.conv.modulation.bias\n",
      "convs.3.noise.weight\n",
      "convs.3.activate.bias\n",
      "convs.4.conv.weight\n",
      "convs.4.conv.blur.kernel\n",
      "convs.4.conv.modulation.weight\n",
      "convs.4.conv.modulation.bias\n",
      "convs.4.noise.weight\n",
      "convs.4.activate.bias\n",
      "convs.5.conv.weight\n",
      "convs.5.conv.modulation.weight\n",
      "convs.5.conv.modulation.bias\n",
      "convs.5.noise.weight\n",
      "convs.5.activate.bias\n",
      "convs.6.conv.weight\n",
      "convs.6.conv.blur.kernel\n",
      "convs.6.conv.modulation.weight\n",
      "convs.6.conv.modulation.bias\n",
      "convs.6.noise.weight\n",
      "convs.6.activate.bias\n",
      "convs.7.conv.weight\n",
      "convs.7.conv.modulation.weight\n",
      "convs.7.conv.modulation.bias\n",
      "convs.7.noise.weight\n",
      "convs.7.activate.bias\n",
      "convs.8.conv.weight\n",
      "convs.8.conv.blur.kernel\n",
      "convs.8.conv.modulation.weight\n",
      "convs.8.conv.modulation.bias\n",
      "convs.8.noise.weight\n",
      "convs.8.activate.bias\n",
      "convs.9.conv.weight\n",
      "convs.9.conv.modulation.weight\n",
      "convs.9.conv.modulation.bias\n",
      "convs.9.noise.weight\n",
      "convs.9.activate.bias\n",
      "convs.10.conv.weight\n",
      "convs.10.conv.blur.kernel\n",
      "convs.10.conv.modulation.weight\n",
      "convs.10.conv.modulation.bias\n",
      "convs.10.noise.weight\n",
      "convs.10.activate.bias\n",
      "convs.11.conv.weight\n",
      "convs.11.conv.modulation.weight\n",
      "convs.11.conv.modulation.bias\n",
      "convs.11.noise.weight\n",
      "convs.11.activate.bias\n",
      "convs.12.conv.weight\n",
      "convs.12.conv.blur.kernel\n",
      "convs.12.conv.modulation.weight\n",
      "convs.12.conv.modulation.bias\n",
      "convs.12.noise.weight\n",
      "convs.12.activate.bias\n",
      "convs.13.conv.weight\n",
      "convs.13.conv.modulation.weight\n",
      "convs.13.conv.modulation.bias\n",
      "convs.13.noise.weight\n",
      "convs.13.activate.bias\n",
      "convs.14.conv.weight\n",
      "convs.14.conv.blur.kernel\n",
      "convs.14.conv.modulation.weight\n",
      "convs.14.conv.modulation.bias\n",
      "convs.14.noise.weight\n",
      "convs.14.activate.bias\n",
      "convs.15.conv.weight\n",
      "convs.15.conv.modulation.weight\n",
      "convs.15.conv.modulation.bias\n",
      "convs.15.noise.weight\n",
      "convs.15.activate.bias\n",
      "to_rgbs.0.bias\n",
      "to_rgbs.0.upsample.kernel\n",
      "to_rgbs.0.conv.weight\n",
      "to_rgbs.0.conv.modulation.weight\n",
      "to_rgbs.0.conv.modulation.bias\n",
      "to_rgbs.1.bias\n",
      "to_rgbs.1.upsample.kernel\n",
      "to_rgbs.1.conv.weight\n",
      "to_rgbs.1.conv.modulation.weight\n",
      "to_rgbs.1.conv.modulation.bias\n",
      "to_rgbs.2.bias\n",
      "to_rgbs.2.upsample.kernel\n",
      "to_rgbs.2.conv.weight\n",
      "to_rgbs.2.conv.modulation.weight\n",
      "to_rgbs.2.conv.modulation.bias\n",
      "to_rgbs.3.bias\n",
      "to_rgbs.3.upsample.kernel\n",
      "to_rgbs.3.conv.weight\n",
      "to_rgbs.3.conv.modulation.weight\n",
      "to_rgbs.3.conv.modulation.bias\n",
      "to_rgbs.4.bias\n",
      "to_rgbs.4.upsample.kernel\n",
      "to_rgbs.4.conv.weight\n",
      "to_rgbs.4.conv.modulation.weight\n",
      "to_rgbs.4.conv.modulation.bias\n",
      "to_rgbs.5.bias\n",
      "to_rgbs.5.upsample.kernel\n",
      "to_rgbs.5.conv.weight\n",
      "to_rgbs.5.conv.modulation.weight\n",
      "to_rgbs.5.conv.modulation.bias\n",
      "to_rgbs.6.bias\n",
      "to_rgbs.6.upsample.kernel\n",
      "to_rgbs.6.conv.weight\n",
      "to_rgbs.6.conv.modulation.weight\n",
      "to_rgbs.6.conv.modulation.bias\n",
      "to_rgbs.7.bias\n",
      "to_rgbs.7.upsample.kernel\n",
      "to_rgbs.7.conv.weight\n",
      "to_rgbs.7.conv.modulation.weight\n",
      "to_rgbs.7.conv.modulation.bias\n",
      "noises.noise_0\n",
      "noises.noise_1\n",
      "noises.noise_2\n",
      "noises.noise_3\n",
      "noises.noise_4\n",
      "noises.noise_5\n",
      "noises.noise_6\n",
      "noises.noise_7\n",
      "noises.noise_8\n",
      "noises.noise_9\n",
      "noises.noise_10\n",
      "noises.noise_11\n",
      "noises.noise_12\n",
      "noises.noise_13\n",
      "noises.noise_14\n",
      "noises.noise_15\n",
      "noises.noise_16\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load('{}/{}{}.pt'.format(root_dir, dataset_name, config))['g_ema']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pre-computed spherical k-means clusters, and provide them to the style interpolator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FactorCatalog' object has no attribute 'M'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-6b191bcb81a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcatalog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'catalog_ffhqE.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.format(dataset_name)) # See comment above regarding additional files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# catalog = torch.load('catalogs/stylegan1_FFHQ.pkl')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msi_wf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStyleInterpolator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcatalog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0msi_wf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_catalog_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/storage/shared/resrchvc/t-yazen/GANLocalEditing/style2_interpolator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, catalog, bias)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cumsum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_order\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_catalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_catalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_catalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FactorCatalog' object has no attribute 'M'"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "catalog = pickle.load(open('catalog_ffhqE.pkl', 'rb'))#.format(dataset_name)) # See comment above regarding additional files\n",
    "# catalog = torch.load('catalogs/stylegan1_FFHQ.pkl')\n",
    "si_wf = StyleInterpolator(catalog, bias=False)\n",
    "si_wf._catalog_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n",
      "(512,)\n",
      "torch.Size([8, 512])\n"
     ]
    }
   ],
   "source": [
    "print(len(catalog.__dict__['M_hoyer']))\n",
    "print(len(catalog.__dict__['M']))\n",
    "print(catalog.__dict__['M_hoyer'][0].shape)\n",
    "print(catalog.__dict__['M'][0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MiniBatchSphericalKMeans(batch_size=200, compute_labels=True, init='k-means++',\n",
       "                         init_size=None, max_iter=100, max_no_improvement=10,\n",
       "                         n_clusters=16, n_init=3, random_state=10,\n",
       "                         reassignment_ratio=0.01, tol=0.0, verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog._factorization\n",
    "# catalog.annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name == 'ffhq':\n",
    "    gs = GANOutputs.from_seed(5, 2001)\n",
    "elif dataset_name == 'cat':\n",
    "    gs = GANOutputs.from_seed((0,33,3,19,34), 6813)\n",
    "batch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 512])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.z.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GANOutputs' object has no attribute 'rgb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-2f3d65c4e69d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mvisutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Target'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mvisutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'References'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GANOutputs' object has no attribute 'rgb'"
     ]
    }
   ],
   "source": [
    "truncation_mean=4096\n",
    "with torch.no_grad():\n",
    "    mean_latent = G.mean_latent(truncation_mean)\n",
    "    rgb, gs.ys, _ = G(gs.z.cuda(), return_latents=True)#, truncation=1, truncation_latent=mean_latent)\n",
    "    rgb = (rgb.clamp(-1, 1) + 1) / 2\n",
    "    rgb = rgb.cpu()\n",
    "    gs.rgb = ptutils.MultiResolutionStore(rgb)\n",
    "    \n",
    "    \n",
    "    gs1 = gs[:1]\n",
    "    gs2 = gs[1:]\n",
    "\n",
    "res=256\n",
    "i, n = 0,4\n",
    "print(gs1.rgb.get(res)[i:i+n].size())\n",
    "visutils.show(gs1.rgb.get(res)[i:i+n].permute(0,2,3,1).cpu(), title='Target')\n",
    "visutils.show(gs2.rgb.get(res)[i:i+n].permute(0,2,3,1).cpu(), title='References')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer object styles from refernces to target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "torch.Size([1, 1, 512, 1, 1]) torch.Size([4, 1, 512, 1, 1]) torch.Size([512])\n",
      "torch.Size([1, 1, 512, 1, 1]) torch.Size([4, 1, 512, 1, 1]) torch.Size([512])\n",
      "torch.Size([1, 1, 512, 1, 1]) torch.Size([4, 1, 512, 1, 1]) torch.Size([512])\n",
      "torch.Size([1, 1, 512, 1, 1]) torch.Size([4, 1, 512, 1, 1]) torch.Size([512])\n",
      "torch.Size([1, 1, 512, 1, 1]) torch.Size([4, 1, 512, 1, 1]) torch.Size([512])\n",
      "torch.Size([1, 1, 512, 1, 1]) torch.Size([4, 1, 512, 1, 1]) torch.Size([512])\n",
      "torch.Size([1, 1, 512, 1, 1]) torch.Size([4, 1, 512, 1, 1]) torch.Size([512])\n",
      "torch.Size([1, 1, 512, 1, 1]) torch.Size([4, 1, 512, 1, 1]) torch.Size([512])\n",
      "torch.Size([1, 1, 512, 1, 1]) torch.Size([4, 1, 512, 1, 1]) torch.Size([256])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (256) must match the size of tensor b (512) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2d6d3875ccb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mpart_gs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mGANOutputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#         print(gs1.ys[0].size(), gs2.ys[0].size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mpart_gs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msi_wf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate_ys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgs2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mrgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mys_to_rgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart_gs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/storage/shared/resrchvc/t-yazen/GANLocalEditing/style2_interpolator.py\u001b[0m in \u001b[0;36minterpolate_ys\u001b[0;34m(self, ys1, ys2, label, rho, epsilon)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         return [self._interpolate_y(ys1[i], ys2[i], self._get_q(i, label, rho[i], epsilon[i]))\n\u001b[0;32m---> 68\u001b[0;31m                 for i in range(len(ys1))]\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/storage/shared/resrchvc/t-yazen/GANLocalEditing/style2_interpolator.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         return [self._interpolate_y(ys1[i], ys2[i], self._get_q(i, label, rho[i], epsilon[i]))\n\u001b[0;32m---> 68\u001b[0;31m                 for i in range(len(ys1))]\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/storage/shared/resrchvc/t-yazen/GANLocalEditing/style2_interpolator.py\u001b[0m in \u001b[0;36m_interpolate_y\u001b[0;34m(self, y1, y2, q)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0my3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0my3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mq\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_bias'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (256) must match the size of tensor b (512) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "part_gs = {}\n",
    "print(len(gs.ys))\n",
    "def get_epsilons(epsilon, low_res_epsilon=0):\n",
    "    epsilons = [epsilon]*len(gs.ys)\n",
    "    for i in range(4): epsilons[i] = low_res_epsilon\n",
    "    return epsilons\n",
    "\n",
    "if dataset_name == 'ffhq':\n",
    "    parts_thresholds = {\n",
    "        'eyes': (0.1, get_epsilons(50, 5)),\n",
    "        'nose': (0.1, get_epsilons(30, 5)),\n",
    "        'mouth': (0.1, get_epsilons(50, 5)),\n",
    "    }\n",
    "\n",
    "elif dataset_name == 'bedrooms':\n",
    "    parts_thresholds = {\n",
    "        'bed': (0.01, get_epsilons(120)),\n",
    "        'pillow': (0.05, get_epsilons(100)),\n",
    "        'window': (0.05, get_epsilons(100)),\n",
    "    }\n",
    "\n",
    "for label, (rho, epsilon) in parts_thresholds.items():\n",
    "        key = (label)\n",
    "        part_gs[key]  = GANOutputs()\n",
    "#         print(gs1.ys[0].size(), gs2.ys[0].size())\n",
    "        part_gs[key].ys = si_wf.interpolate_ys(gs1.ys, gs2.ys, label, rho, epsilon)\n",
    "        with torch.no_grad():\n",
    "                rgb = G.ys_to_rgb(part_gs[key].ys)\n",
    "                rgb = (rgb.clamp(-1, 1) + 1) / 2\n",
    "                rgb = rgb.cpu()\n",
    "                part_gs[key].rgb = ptutils.MultiResolutionStore(rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 256\n",
    "visutils.part_grid(gs1.rgb.get(res), gs2.rgb.get(res), {k: v.rgb.get(res) for k,v in part_gs.items()});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the MSE in CIELAB color-space, between the edited output and the target image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 256\n",
    "normalize = lambda x: x/x.max()\n",
    "visutils.part_grid(gs1.rgb.get(res), gs2.rgb.get(res),\n",
    "                 {k: normalize(cielab.squared_error(v.rgb.get(res), gs1.rgb.get(res))) for k,v in part_gs.items()});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
